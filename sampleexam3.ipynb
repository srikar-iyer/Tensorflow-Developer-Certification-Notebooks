{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YTwoCXQBbdq"
      },
      "source": [
        "# PROBLEM C1\n",
        "\n",
        " Given two arrays, train a neural network model to match the X to the Y.\n",
        " Predict the model with new values of X [-2.0, 10.0]\n",
        " We provide the model prediction, do not change the code.\n",
        "\n",
        " The test infrastructure expects a trained model that accepts\n",
        " an input shape of [1]\n",
        " Do not use lambda layers in your model.\n",
        "\n",
        " Please be aware that this is a linear model.\n",
        " We will test your model with values in a range as defined in the array to make sure your model is linear.\n",
        "\n",
        "# Desired loss (MSE) < 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l97ZYLpk76dh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LyNMMOWaBcZh"
      },
      "outputs": [],
      "source": [
        "def solution_C1():\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    X = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0], dtype=float)\n",
        "    Y = np.array([0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5], dtype=float)\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    normalizer = tf.keras.layers.Normalization(axis=None, input_shape=(1,), name=\"normalizer\")\n",
        "    normalizer.adapt(X)\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(normalizer)\n",
        "    model.add(keras.layers.Dense(32))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "    model.fit(X, Y, epochs=1000, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)])\n",
        "\n",
        "    # Evaluate the model and check if the loss is less than 1e-4.\n",
        "    loss, mse = model.evaluate(X, Y)\n",
        "    assert mse < 1e-4, \"\\033[91mDesired loss not achieved! Got {:.6f} MSE.\\033[0m\".format(loss)\n",
        "\n",
        "    print(model.predict(np.array([-2.0, 10.0])))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDdiGZqgBccv",
        "outputId": "9e3467bd-842e-406e-aff7-fc8a9a227bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\srini\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\normalization.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649ms/step - loss: 5.3661 - mse: 5.3661\n",
            "Epoch 2/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.2995 - mse: 5.2995\n",
            "Epoch 3/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.2335 - mse: 5.2335\n",
            "Epoch 4/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1680 - mse: 5.1680\n",
            "Epoch 5/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.1030 - mse: 5.1030\n",
            "Epoch 6/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0386 - mse: 5.0386\n",
            "Epoch 7/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.9747 - mse: 4.9747\n",
            "Epoch 8/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.9113 - mse: 4.9113\n",
            "Epoch 9/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.8486 - mse: 4.8486\n",
            "Epoch 10/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.7863 - mse: 4.7863\n",
            "Epoch 11/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.7247 - mse: 4.7247\n",
            "Epoch 12/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.6636 - mse: 4.6636\n",
            "Epoch 13/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.6031 - mse: 4.6031\n",
            "Epoch 14/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.5432 - mse: 4.5432\n",
            "Epoch 15/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.4839 - mse: 4.4839\n",
            "Epoch 16/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.4251 - mse: 4.4251\n",
            "Epoch 17/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3670 - mse: 4.3670\n",
            "Epoch 18/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.3094 - mse: 4.3094\n",
            "Epoch 19/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.2524 - mse: 4.2524\n",
            "Epoch 20/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1959 - mse: 4.1959\n",
            "Epoch 21/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.1401 - mse: 4.1401\n",
            "Epoch 22/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0848 - mse: 4.0848\n",
            "Epoch 23/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0301 - mse: 4.0301\n",
            "Epoch 24/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.9760 - mse: 3.9760\n",
            "Epoch 25/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.9224 - mse: 3.9224\n",
            "Epoch 26/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.8694 - mse: 3.8694\n",
            "Epoch 27/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.8170 - mse: 3.8170\n",
            "Epoch 28/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.7651 - mse: 3.7651\n",
            "Epoch 29/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.7138 - mse: 3.7138\n",
            "Epoch 30/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.6630 - mse: 3.6630\n",
            "Epoch 31/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6127 - mse: 3.6127\n",
            "Epoch 32/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.5630 - mse: 3.5630\n",
            "Epoch 33/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.5139 - mse: 3.5139\n",
            "Epoch 34/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.4653 - mse: 3.4653\n",
            "Epoch 35/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.4172 - mse: 3.4172\n",
            "Epoch 36/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.3696 - mse: 3.3696\n",
            "Epoch 37/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3225 - mse: 3.3225\n",
            "Epoch 38/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2760 - mse: 3.2760\n",
            "Epoch 39/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2299 - mse: 3.2299\n",
            "Epoch 40/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1844 - mse: 3.1844\n",
            "Epoch 41/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.1394 - mse: 3.1394\n",
            "Epoch 42/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0948 - mse: 3.0948\n",
            "Epoch 43/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0507 - mse: 3.0507\n",
            "Epoch 44/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.0072 - mse: 3.0072\n",
            "Epoch 45/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.9641 - mse: 2.9641\n",
            "Epoch 46/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.9214 - mse: 2.9214\n",
            "Epoch 47/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.8793 - mse: 2.8793\n",
            "Epoch 48/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.8376 - mse: 2.8376\n",
            "Epoch 49/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7963 - mse: 2.7963\n",
            "Epoch 50/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.7555 - mse: 2.7555\n",
            "Epoch 51/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7152 - mse: 2.7152\n",
            "Epoch 52/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6752 - mse: 2.6752\n",
            "Epoch 53/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6358 - mse: 2.6358\n",
            "Epoch 54/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5967 - mse: 2.5967\n",
            "Epoch 55/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5581 - mse: 2.5581\n",
            "Epoch 56/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5199 - mse: 2.5199\n",
            "Epoch 57/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.4821 - mse: 2.4821\n",
            "Epoch 58/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.4447 - mse: 2.4447\n",
            "Epoch 59/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4078 - mse: 2.4078\n",
            "Epoch 60/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.3712 - mse: 2.3712\n",
            "Epoch 61/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.3350 - mse: 2.3350\n",
            "Epoch 62/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.2992 - mse: 2.2992\n",
            "Epoch 63/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2639 - mse: 2.2639\n",
            "Epoch 64/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2288 - mse: 2.2288\n",
            "Epoch 65/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.1942 - mse: 2.1942\n",
            "Epoch 66/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.1600 - mse: 2.1600\n",
            "Epoch 67/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1261 - mse: 2.1261\n",
            "Epoch 68/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.0925 - mse: 2.0925\n",
            "Epoch 69/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.0594 - mse: 2.0594\n",
            "Epoch 70/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0266 - mse: 2.0266\n",
            "Epoch 71/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9941 - mse: 1.9941\n",
            "Epoch 72/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9620 - mse: 1.9620\n",
            "Epoch 73/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.9303 - mse: 1.9303\n",
            "Epoch 74/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8989 - mse: 1.8989\n",
            "Epoch 75/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8678 - mse: 1.8678\n",
            "Epoch 76/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8371 - mse: 1.8371\n",
            "Epoch 77/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8067 - mse: 1.8067\n",
            "Epoch 78/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7766 - mse: 1.7766\n",
            "Epoch 79/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7469 - mse: 1.7469\n",
            "Epoch 80/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7174 - mse: 1.7174\n",
            "Epoch 81/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6883 - mse: 1.6883\n",
            "Epoch 82/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6595 - mse: 1.6595\n",
            "Epoch 83/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6311 - mse: 1.6311\n",
            "Epoch 84/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6029 - mse: 1.6029\n",
            "Epoch 85/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5751 - mse: 1.5751\n",
            "Epoch 86/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5475 - mse: 1.5475\n",
            "Epoch 87/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5203 - mse: 1.5203\n",
            "Epoch 88/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4933 - mse: 1.4933\n",
            "Epoch 89/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4667 - mse: 1.4667\n",
            "Epoch 90/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4404 - mse: 1.4404\n",
            "Epoch 91/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4143 - mse: 1.4143\n",
            "Epoch 92/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3886 - mse: 1.3886\n",
            "Epoch 93/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3631 - mse: 1.3631\n",
            "Epoch 94/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3379 - mse: 1.3379\n",
            "Epoch 95/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3130 - mse: 1.3130\n",
            "Epoch 96/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2884 - mse: 1.2884\n",
            "Epoch 97/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2641 - mse: 1.2641\n",
            "Epoch 98/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2401 - mse: 1.2401\n",
            "Epoch 99/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2163 - mse: 1.2163\n",
            "Epoch 100/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1929 - mse: 1.1929\n",
            "Epoch 101/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1697 - mse: 1.1697\n",
            "Epoch 102/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1468 - mse: 1.1468\n",
            "Epoch 103/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1241 - mse: 1.1241\n",
            "Epoch 104/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1017 - mse: 1.1017\n",
            "Epoch 105/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0796 - mse: 1.0796\n",
            "Epoch 106/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0578 - mse: 1.0578\n",
            "Epoch 107/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0363 - mse: 1.0363\n",
            "Epoch 108/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0150 - mse: 1.0150\n",
            "Epoch 109/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9939 - mse: 0.9939\n",
            "Epoch 110/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9732 - mse: 0.9732\n",
            "Epoch 111/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.9527 - mse: 0.9527\n",
            "Epoch 112/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9325 - mse: 0.9325\n",
            "Epoch 113/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9125 - mse: 0.9125\n",
            "Epoch 114/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8928 - mse: 0.8928\n",
            "Epoch 115/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8734 - mse: 0.8734\n",
            "Epoch 116/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8542 - mse: 0.8542\n",
            "Epoch 117/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.8353 - mse: 0.8353\n",
            "Epoch 118/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.8167 - mse: 0.8167\n",
            "Epoch 119/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.7983 - mse: 0.7983\n",
            "Epoch 120/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7801 - mse: 0.7801\n",
            "Epoch 121/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7623 - mse: 0.7623\n",
            "Epoch 122/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.7446 - mse: 0.7446\n",
            "Epoch 123/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7273 - mse: 0.7273\n",
            "Epoch 124/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.7102 - mse: 0.7102\n",
            "Epoch 125/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6933 - mse: 0.6933\n",
            "Epoch 126/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6767 - mse: 0.6767\n",
            "Epoch 127/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6604 - mse: 0.6604\n",
            "Epoch 128/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6443 - mse: 0.6443\n",
            "Epoch 129/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6284 - mse: 0.6284\n",
            "Epoch 130/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6129 - mse: 0.6129\n",
            "Epoch 131/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5975 - mse: 0.5975\n",
            "Epoch 132/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5824 - mse: 0.5824\n",
            "Epoch 133/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5676 - mse: 0.5676\n",
            "Epoch 134/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5530 - mse: 0.5530\n",
            "Epoch 135/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5386 - mse: 0.5386\n",
            "Epoch 136/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5245 - mse: 0.5245\n",
            "Epoch 137/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5107 - mse: 0.5107\n",
            "Epoch 138/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4970 - mse: 0.4970\n",
            "Epoch 139/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4837 - mse: 0.4837\n",
            "Epoch 140/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4705 - mse: 0.4705\n",
            "Epoch 141/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4576 - mse: 0.4576\n",
            "Epoch 142/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4450 - mse: 0.4450\n",
            "Epoch 143/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4326 - mse: 0.4326\n",
            "Epoch 144/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4204 - mse: 0.4204\n",
            "Epoch 145/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.4084 - mse: 0.4084\n",
            "Epoch 146/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3967 - mse: 0.3967\n",
            "Epoch 147/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3852 - mse: 0.3852\n",
            "Epoch 148/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3740 - mse: 0.3740\n",
            "Epoch 149/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3629 - mse: 0.3629\n",
            "Epoch 150/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3521 - mse: 0.3521\n",
            "Epoch 151/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3416 - mse: 0.3416\n",
            "Epoch 152/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3312 - mse: 0.3312\n",
            "Epoch 153/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3211 - mse: 0.3211\n",
            "Epoch 154/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3112 - mse: 0.3112\n",
            "Epoch 155/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3015 - mse: 0.3015\n",
            "Epoch 156/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2920 - mse: 0.2920\n",
            "Epoch 157/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2828 - mse: 0.2828\n",
            "Epoch 158/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2737 - mse: 0.2737\n",
            "Epoch 159/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2649 - mse: 0.2649\n",
            "Epoch 160/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2563 - mse: 0.2563\n",
            "Epoch 161/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2479 - mse: 0.2479\n",
            "Epoch 162/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2397 - mse: 0.2397\n",
            "Epoch 163/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2316 - mse: 0.2316\n",
            "Epoch 164/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2238 - mse: 0.2238\n",
            "Epoch 165/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2162 - mse: 0.2162\n",
            "Epoch 166/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2088 - mse: 0.2088\n",
            "Epoch 167/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2016 - mse: 0.2016\n",
            "Epoch 168/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1945 - mse: 0.1945\n",
            "Epoch 169/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1877 - mse: 0.1877\n",
            "Epoch 170/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1810 - mse: 0.1810\n",
            "Epoch 171/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1745 - mse: 0.1745\n",
            "Epoch 172/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1682 - mse: 0.1682\n",
            "Epoch 173/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1621 - mse: 0.1621\n",
            "Epoch 174/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1561 - mse: 0.1561\n",
            "Epoch 175/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1503 - mse: 0.1503\n",
            "Epoch 176/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1447 - mse: 0.1447\n",
            "Epoch 177/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1392 - mse: 0.1392\n",
            "Epoch 178/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1339 - mse: 0.1339\n",
            "Epoch 179/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1288 - mse: 0.1288\n",
            "Epoch 180/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1238 - mse: 0.1238\n",
            "Epoch 181/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1190 - mse: 0.1190\n",
            "Epoch 182/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1143 - mse: 0.1143\n",
            "Epoch 183/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1097 - mse: 0.1097\n",
            "Epoch 184/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1054 - mse: 0.1054\n",
            "Epoch 185/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1011 - mse: 0.1011\n",
            "Epoch 186/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0970 - mse: 0.0970\n",
            "Epoch 187/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0930 - mse: 0.0930\n",
            "Epoch 188/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0892 - mse: 0.0892\n",
            "Epoch 189/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0855 - mse: 0.0855\n",
            "Epoch 190/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0819 - mse: 0.0819\n",
            "Epoch 191/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0784 - mse: 0.0784\n",
            "Epoch 192/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0751 - mse: 0.0751\n",
            "Epoch 193/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0718 - mse: 0.0718\n",
            "Epoch 194/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0687 - mse: 0.0687\n",
            "Epoch 195/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0657 - mse: 0.0657\n",
            "Epoch 196/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0628 - mse: 0.0628\n",
            "Epoch 197/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0601 - mse: 0.0601\n",
            "Epoch 198/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0574 - mse: 0.0574\n",
            "Epoch 199/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0548 - mse: 0.0548\n",
            "Epoch 200/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0523 - mse: 0.0523\n",
            "Epoch 201/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0499 - mse: 0.0499\n",
            "Epoch 202/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0476 - mse: 0.0476\n",
            "Epoch 203/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0454 - mse: 0.0454\n",
            "Epoch 204/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0433 - mse: 0.0433\n",
            "Epoch 205/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0413 - mse: 0.0413\n",
            "Epoch 206/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0393 - mse: 0.0393\n",
            "Epoch 207/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0374 - mse: 0.0374\n",
            "Epoch 208/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0356 - mse: 0.0356\n",
            "Epoch 209/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0339 - mse: 0.0339\n",
            "Epoch 210/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0322 - mse: 0.0322\n",
            "Epoch 211/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0307 - mse: 0.0307\n",
            "Epoch 212/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0291 - mse: 0.0291\n",
            "Epoch 213/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0277 - mse: 0.0277\n",
            "Epoch 214/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0263 - mse: 0.0263\n",
            "Epoch 215/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0250 - mse: 0.0250\n",
            "Epoch 216/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0237 - mse: 0.0237\n",
            "Epoch 217/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0225 - mse: 0.0225\n",
            "Epoch 218/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0213 - mse: 0.0213\n",
            "Epoch 219/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0202 - mse: 0.0202\n",
            "Epoch 220/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0192 - mse: 0.0192\n",
            "Epoch 221/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0182 - mse: 0.0182\n",
            "Epoch 222/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0172 - mse: 0.0172\n",
            "Epoch 223/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0163 - mse: 0.0163\n",
            "Epoch 224/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0154 - mse: 0.0154\n",
            "Epoch 225/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0146 - mse: 0.0146\n",
            "Epoch 226/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0138 - mse: 0.0138\n",
            "Epoch 227/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0130 - mse: 0.0130\n",
            "Epoch 228/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0123 - mse: 0.0123\n",
            "Epoch 229/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0116 - mse: 0.0116\n",
            "Epoch 230/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0110 - mse: 0.0110\n",
            "Epoch 231/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0104 - mse: 0.0104\n",
            "Epoch 232/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0098 - mse: 0.0098\n",
            "Epoch 233/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0092 - mse: 0.0092\n",
            "Epoch 234/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0087 - mse: 0.0087\n",
            "Epoch 235/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0082 - mse: 0.0082\n",
            "Epoch 236/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0077 - mse: 0.0077\n",
            "Epoch 237/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0073 - mse: 0.0073\n",
            "Epoch 238/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0068 - mse: 0.0068\n",
            "Epoch 239/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0064 - mse: 0.0064\n",
            "Epoch 240/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0061 - mse: 0.0061\n",
            "Epoch 241/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0057 - mse: 0.0057\n",
            "Epoch 242/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0054 - mse: 0.0054\n",
            "Epoch 243/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0050 - mse: 0.0050\n",
            "Epoch 244/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0047 - mse: 0.0047\n",
            "Epoch 245/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0044 - mse: 0.0044\n",
            "Epoch 246/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0042 - mse: 0.0042\n",
            "Epoch 247/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0039 - mse: 0.0039\n",
            "Epoch 248/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0037 - mse: 0.0037\n",
            "Epoch 249/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0034 - mse: 0.0034\n",
            "Epoch 250/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0032 - mse: 0.0032\n",
            "Epoch 251/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 252/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 253/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 254/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0025 - mse: 0.0025\n",
            "Epoch 255/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0023 - mse: 0.0023\n",
            "Epoch 256/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - mse: 0.0022\n",
            "Epoch 257/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0020 - mse: 0.0020\n",
            "Epoch 258/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0019 - mse: 0.0019\n",
            "Epoch 259/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018 - mse: 0.0018\n",
            "Epoch 260/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0017 - mse: 0.0017\n",
            "Epoch 261/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0015 - mse: 0.0015\n",
            "Epoch 262/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 263/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 264/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 265/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0012 - mse: 0.0012\n",
            "Epoch 266/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - mse: 0.0011\n",
            "Epoch 267/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0010 - mse: 0.0010\n",
            "Epoch 268/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.4206e-04 - mse: 9.4206e-04\n",
            "Epoch 269/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.7660e-04 - mse: 8.7660e-04\n",
            "Epoch 270/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.1537e-04 - mse: 8.1537e-04\n",
            "Epoch 271/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.5813e-04 - mse: 7.5813e-04\n",
            "Epoch 272/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.0463e-04 - mse: 7.0463e-04\n",
            "Epoch 273/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.5465e-04 - mse: 6.5465e-04\n",
            "Epoch 274/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.0797e-04 - mse: 6.0797e-04\n",
            "Epoch 275/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.6440e-04 - mse: 5.6440e-04\n",
            "Epoch 276/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.2376e-04 - mse: 5.2376e-04\n",
            "Epoch 277/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.8584e-04 - mse: 4.8584e-04\n",
            "Epoch 278/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.5049e-04 - mse: 4.5049e-04\n",
            "Epoch 279/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1755e-04 - mse: 4.1755e-04\n",
            "Epoch 280/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8686e-04 - mse: 3.8686e-04\n",
            "Epoch 281/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.5829e-04 - mse: 3.5829e-04\n",
            "Epoch 282/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3169e-04 - mse: 3.3169e-04\n",
            "Epoch 283/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.0694e-04 - mse: 3.0694e-04\n",
            "Epoch 284/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8393e-04 - mse: 2.8393e-04\n",
            "Epoch 285/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6253e-04 - mse: 2.6253e-04\n",
            "Epoch 286/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4265e-04 - mse: 2.4265e-04\n",
            "Epoch 287/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.2418e-04 - mse: 2.2418e-04\n",
            "Epoch 288/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0703e-04 - mse: 2.0703e-04\n",
            "Epoch 289/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9111e-04 - mse: 1.9111e-04\n",
            "Epoch 290/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7635e-04 - mse: 1.7635e-04\n",
            "Epoch 291/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6266e-04 - mse: 1.6266e-04\n",
            "Epoch 292/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4996e-04 - mse: 1.4996e-04\n",
            "Epoch 293/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3820e-04 - mse: 1.3820e-04\n",
            "Epoch 294/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2731e-04 - mse: 1.2731e-04\n",
            "Epoch 295/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1723e-04 - mse: 1.1723e-04\n",
            "Epoch 296/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0789e-04 - mse: 1.0789e-04\n",
            "Epoch 297/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.9263e-05 - mse: 9.9263e-05\n",
            "Epoch 298/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.1282e-05 - mse: 9.1282e-05\n",
            "Epoch 299/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.3908e-05 - mse: 8.3908e-05\n",
            "Epoch 300/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.7092e-05 - mse: 7.7092e-05\n",
            "Epoch 301/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.0801e-05 - mse: 7.0801e-05\n",
            "Epoch 302/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.4993e-05 - mse: 6.4993e-05\n",
            "Epoch 303/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.9636e-05 - mse: 5.9636e-05\n",
            "Epoch 304/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.4695e-05 - mse: 5.4695e-05\n",
            "Epoch 305/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0141e-05 - mse: 5.0141e-05\n",
            "Epoch 306/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.5945e-05 - mse: 4.5945e-05\n",
            "Epoch 307/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.2080e-05 - mse: 4.2080e-05\n",
            "Epoch 308/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.8524e-05 - mse: 3.8524e-05\n",
            "Epoch 309/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5250e-05 - mse: 3.5250e-05\n",
            "Epoch 310/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2240e-05 - mse: 3.2240e-05\n",
            "Epoch 311/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.9472e-05 - mse: 2.9472e-05\n",
            "Epoch 312/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6930e-05 - mse: 2.6930e-05\n",
            "Epoch 313/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.4593e-05 - mse: 2.4593e-05\n",
            "Epoch 314/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.2450e-05 - mse: 2.2450e-05\n",
            "Epoch 315/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.0482e-05 - mse: 2.0482e-05\n",
            "Epoch 316/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8679e-05 - mse: 1.8679e-05\n",
            "Epoch 317/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7025e-05 - mse: 1.7025e-05\n",
            "Epoch 318/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5510e-05 - mse: 1.5510e-05\n",
            "Epoch 319/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4122e-05 - mse: 1.4122e-05\n",
            "Epoch 320/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2851e-05 - mse: 1.2851e-05\n",
            "Epoch 321/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1689e-05 - mse: 1.1689e-05\n",
            "Epoch 322/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0626e-05 - mse: 1.0626e-05\n",
            "Epoch 323/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.6548e-06 - mse: 9.6548e-06\n",
            "Epoch 324/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.7674e-06 - mse: 8.7674e-06\n",
            "Epoch 325/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.9573e-06 - mse: 7.9573e-06\n",
            "Epoch 326/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.2175e-06 - mse: 7.2175e-06\n",
            "Epoch 327/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.5435e-06 - mse: 6.5435e-06\n",
            "Epoch 328/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.9289e-06 - mse: 5.9289e-06\n",
            "Epoch 329/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3688e-06 - mse: 5.3688e-06\n",
            "Epoch 330/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.8587e-06 - mse: 4.8587e-06\n",
            "Epoch 331/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.3945e-06 - mse: 4.3945e-06\n",
            "Epoch 332/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9722e-06 - mse: 3.9722e-06\n",
            "Epoch 333/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.5883e-06 - mse: 3.5883e-06\n",
            "Epoch 334/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2392e-06 - mse: 3.2392e-06\n",
            "Epoch 335/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9229e-06 - mse: 2.9229e-06\n",
            "Epoch 336/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6354e-06 - mse: 2.6354e-06\n",
            "Epoch 337/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3743e-06 - mse: 2.3743e-06\n",
            "Epoch 338/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.1379e-06 - mse: 2.1379e-06\n",
            "Epoch 339/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.9239e-06 - mse: 1.9239e-06\n",
            "Epoch 340/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7300e-06 - mse: 1.7300e-06\n",
            "Epoch 341/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5544e-06 - mse: 1.5544e-06\n",
            "Epoch 342/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3958e-06 - mse: 1.3958e-06\n",
            "Epoch 343/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2524e-06 - mse: 1.2524e-06\n",
            "Epoch 344/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1230e-06 - mse: 1.1230e-06\n",
            "Epoch 345/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0061e-06 - mse: 1.0061e-06\n",
            "Epoch 346/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.0069e-07 - mse: 9.0069e-07\n",
            "Epoch 347/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.0587e-07 - mse: 8.0587e-07\n",
            "Epoch 348/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.2028e-07 - mse: 7.2028e-07\n",
            "Epoch 349/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.4335e-07 - mse: 6.4335e-07\n",
            "Epoch 350/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.7407e-07 - mse: 5.7407e-07\n",
            "Epoch 351/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.1181e-07 - mse: 5.1181e-07\n",
            "Epoch 352/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.5611e-07 - mse: 4.5611e-07\n",
            "Epoch 353/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.0595e-07 - mse: 4.0595e-07\n",
            "Epoch 354/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.6103e-07 - mse: 3.6103e-07\n",
            "Epoch 355/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2073e-07 - mse: 3.2073e-07\n",
            "Epoch 356/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.8464e-07 - mse: 2.8464e-07\n",
            "Epoch 357/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.5229e-07 - mse: 2.5229e-07\n",
            "Epoch 358/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2347e-07 - mse: 2.2347e-07\n",
            "Epoch 359/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9781e-07 - mse: 1.9781e-07\n",
            "Epoch 360/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7487e-07 - mse: 1.7487e-07\n",
            "Epoch 361/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5440e-07 - mse: 1.5440e-07\n",
            "Epoch 362/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3617e-07 - mse: 1.3617e-07\n",
            "Epoch 363/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1997e-07 - mse: 1.1997e-07\n",
            "Epoch 364/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0558e-07 - mse: 1.0558e-07\n",
            "Epoch 365/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.2791e-08 - mse: 9.2791e-08\n",
            "Epoch 366/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.1408e-08 - mse: 8.1408e-08\n",
            "Epoch 367/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.1365e-08 - mse: 7.1365e-08\n",
            "Epoch 368/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.2464e-08 - mse: 6.2464e-08\n",
            "Epoch 369/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.4589e-08 - mse: 5.4589e-08\n",
            "Epoch 370/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.7602e-08 - mse: 4.7602e-08\n",
            "Epoch 371/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.1525e-08 - mse: 4.1525e-08\n",
            "Epoch 372/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6116e-08 - mse: 3.6116e-08\n",
            "Epoch 373/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1376e-08 - mse: 3.1376e-08\n",
            "Epoch 374/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7190e-08 - mse: 2.7190e-08\n",
            "Epoch 375/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.3526e-08 - mse: 2.3526e-08\n",
            "Epoch 376/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.0331e-08 - mse: 2.0331e-08\n",
            "Epoch 377/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7520e-08 - mse: 1.7520e-08\n",
            "Epoch 378/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5083e-08 - mse: 1.5083e-08\n",
            "Epoch 379/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2913e-08 - mse: 1.2913e-08\n",
            "Epoch 380/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1086e-08 - mse: 1.1086e-08\n",
            "Epoch 381/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.4498e-09 - mse: 9.4498e-09\n",
            "Epoch 382/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.0641e-09 - mse: 8.0641e-09\n",
            "Epoch 383/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.8394e-09 - mse: 6.8394e-09\n",
            "Epoch 384/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.8070e-09 - mse: 5.8070e-09\n",
            "Epoch 385/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.9004e-09 - mse: 4.9004e-09\n",
            "Epoch 386/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.1262e-09 - mse: 4.1262e-09\n",
            "Epoch 387/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.4517e-09 - mse: 3.4517e-09\n",
            "Epoch 388/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.8835e-09 - mse: 2.8835e-09\n",
            "Epoch 389/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.3947e-09 - mse: 2.3947e-09\n",
            "Epoch 390/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9870e-09 - mse: 1.9870e-09\n",
            "Epoch 391/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6309e-09 - mse: 1.6309e-09\n",
            "Epoch 392/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3356e-09 - mse: 1.3356e-09\n",
            "Epoch 393/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0919e-09 - mse: 1.0919e-09\n",
            "Epoch 394/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.7766e-10 - mse: 8.7766e-10\n",
            "Epoch 395/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.0834e-10 - mse: 7.0834e-10\n",
            "Epoch 396/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.6190e-10 - mse: 5.6190e-10\n",
            "Epoch 397/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.4493e-10 - mse: 4.4493e-10\n",
            "Epoch 398/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.4245e-10 - mse: 3.4245e-10\n",
            "Epoch 399/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.6569e-10 - mse: 2.6569e-10\n",
            "Epoch 400/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0116e-10 - mse: 2.0116e-10\n",
            "Epoch 401/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4891e-10 - mse: 1.4891e-10\n",
            "Epoch 402/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.0905e-10 - mse: 1.0905e-10\n",
            "Epoch 403/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.7149e-11 - mse: 7.7149e-11\n",
            "Epoch 404/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.2443e-11 - mse: 5.2443e-11\n",
            "Epoch 405/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3956e-11 - mse: 3.3956e-11\n",
            "Epoch 406/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0974e-11 - mse: 2.0974e-11\n",
            "Epoch 407/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1509e-11 - mse: 1.1509e-11\n",
            "Epoch 408/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.5082e-12 - mse: 5.5082e-12\n",
            "Epoch 409/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.9149e-12 - mse: 1.9149e-12\n",
            "Epoch 410/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9246e-13 - mse: 2.9246e-13\n",
            "Epoch 411/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.9476e-14 - mse: 9.9476e-14\n",
            "Epoch 412/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.7904e-13 - mse: 8.7904e-13\n",
            "Epoch 413/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.5864e-12 - mse: 2.5864e-12\n",
            "Epoch 414/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.8418e-12 - mse: 4.8418e-12\n",
            "Epoch 415/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.4384e-12 - mse: 7.4384e-12\n",
            "Epoch 416/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.7735e-12 - mse: 9.7735e-12\n",
            "Epoch 417/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2331e-11 - mse: 1.2331e-11\n",
            "Epoch 418/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4619e-11 - mse: 1.4619e-11\n",
            "Epoch 419/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6596e-11 - mse: 1.6596e-11\n",
            "Epoch 420/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8937e-11 - mse: 1.8937e-11\n",
            "Epoch 421/1000\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.1719e-11 - mse: 2.1719e-11\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2.2614e-11 - mse: 2.2614e-11\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[4.9471855e-06]\n",
            " [6.0000043e+00]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C1()\n",
        "    model.save(\"model_C1.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZhFVtyyBc3J"
      },
      "source": [
        "# PROBLEM C2\n",
        "\n",
        " Create a classifier for the MNIST Handwritten digit dataset.\n",
        " The test will expect it to classify 10 classes.\n",
        "\n",
        " Don't use lambda layers in your model.\n",
        "\n",
        "# Desired accuracy AND validation_accuracy > 91%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A3Zr1lmCBdJX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B5WXb4mBBdPJ"
      },
      "outputs": [],
      "source": [
        "def solution_C2():\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "\n",
        "    (training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "    training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "    training_images=training_images / 255.0\n",
        "    test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "    test_images=test_images/255.0\n",
        "\n",
        "    # DEFINE YOUR MODEL HERE\n",
        "    # End with 10 Neuron Dense, activated by softmax\n",
        "    model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # COMPILE MODEL HERE\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    # TRAIN YOUR MODEL HERE\n",
        "    model.fit(training_images, training_labels, validation_data=(test_images, test_labels), epochs=10, verbose=1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yeksi3JCBdWn",
        "outputId": "2d8d63b9-5009-4f83-a33e-0a94b6c465b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\srini\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.2951 - val_accuracy: 0.9839 - val_loss: 0.0465\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0442 - val_accuracy: 0.9864 - val_loss: 0.0400\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0288 - val_accuracy: 0.9857 - val_loss: 0.0482\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0185 - val_accuracy: 0.9908 - val_loss: 0.0281\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0129 - val_accuracy: 0.9919 - val_loss: 0.0280\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0103 - val_accuracy: 0.9883 - val_loss: 0.0420\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0093 - val_accuracy: 0.9918 - val_loss: 0.0304\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 0.9912 - val_loss: 0.0361\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0050 - val_accuracy: 0.9921 - val_loss: 0.0343\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0066 - val_accuracy: 0.9898 - val_loss: 0.0394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C2()\n",
        "    model.save(\"model_C2.h5\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzBGBVSXBdn1"
      },
      "source": [
        "# PROBLEM C3\n",
        "\n",
        " Build a CNN based classifier for Cats vs Dogs dataset.\n",
        " Your input layer should accept 150x150 with 3 bytes color as the input shape.\n",
        " This is unlabeled data, use ImageDataGenerator to automatically label it.\n",
        " Don't use lambda layers in your model.\n",
        "\n",
        " The dataset used in this problem is originally published in https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "\n",
        "# Desired accuracy and validation_accuracy > 72%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fsBFGhdFBd3L"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qjneKOcCBd8p"
      },
      "outputs": [],
      "source": [
        "def solution_C3():\n",
        "    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/cats_and_dogs.zip'\n",
        "    urllib.request.urlretrieve(data_url, 'cats_and_dogs.zip')\n",
        "    local_file = 'cats_and_dogs.zip'\n",
        "    zip_ref = zipfile.ZipFile(local_file, 'r')\n",
        "    zip_ref.extractall('data/')\n",
        "    zip_ref.close()\n",
        "\n",
        "    BASE_DIR = 'data/cats_and_dogs_filtered'\n",
        "    train_dir = os.path.join(BASE_DIR, 'train')\n",
        "    validation_dir = os.path.join(BASE_DIR, 'validation')\n",
        "\n",
        "    train_datagenerator = ImageDataGenerator(rescale=1. / 255, horizontal_flip=True, zoom_range=0.2, shear_range=0.1,\n",
        "                                       rotation_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
        "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    # YOUR IMAGE SIZE SHOULD BE 150x150\n",
        "    # Make sure you used \"categorical\"\n",
        "    train_generator = train_datagenerator.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=64,\n",
        "        class_mode='binary')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=16,\n",
        "        class_mode='binary')\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # YOUR CODE HERE, end with a Neuron Dense, activated by 'sigmoid'\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  optimizer='nadam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        epochs=30,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5,\n",
        "                                                        min_lr=0.00001)])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItJMhb2zBeCF",
        "outputId": "da089e40-50a4-4ae0-d2cc-48c6959d7138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\srini\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 362ms/step - accuracy: 0.4974 - loss: 1.8191 - val_accuracy: 0.5040 - val_loss: 0.6860 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 356ms/step - accuracy: 0.5563 - loss: 0.6827 - val_accuracy: 0.6630 - val_loss: 0.6394 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 367ms/step - accuracy: 0.6268 - loss: 0.6477 - val_accuracy: 0.6680 - val_loss: 0.5966 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 364ms/step - accuracy: 0.6849 - loss: 0.5962 - val_accuracy: 0.6890 - val_loss: 0.5885 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 371ms/step - accuracy: 0.6819 - loss: 0.5943 - val_accuracy: 0.6720 - val_loss: 0.5844 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 381ms/step - accuracy: 0.7200 - loss: 0.5640 - val_accuracy: 0.7100 - val_loss: 0.5475 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 373ms/step - accuracy: 0.7207 - loss: 0.5573 - val_accuracy: 0.7350 - val_loss: 0.5360 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 632ms/step - accuracy: 0.7066 - loss: 0.5769 - val_accuracy: 0.7280 - val_loss: 0.5333 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 357ms/step - accuracy: 0.7476 - loss: 0.5251 - val_accuracy: 0.7090 - val_loss: 0.5503 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.7256 - loss: 0.5391\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 361ms/step - accuracy: 0.7258 - loss: 0.5390 - val_accuracy: 0.7320 - val_loss: 0.5233 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 383ms/step - accuracy: 0.7359 - loss: 0.5286 - val_accuracy: 0.7140 - val_loss: 0.5263 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 374ms/step - accuracy: 0.7542 - loss: 0.5024 - val_accuracy: 0.7370 - val_loss: 0.5241 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 388ms/step - accuracy: 0.7649 - loss: 0.4969 - val_accuracy: 0.7330 - val_loss: 0.5376 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 388ms/step - accuracy: 0.7524 - loss: 0.4828 - val_accuracy: 0.7390 - val_loss: 0.5038 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 380ms/step - accuracy: 0.7463 - loss: 0.5031 - val_accuracy: 0.7370 - val_loss: 0.5323 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 375ms/step - accuracy: 0.7710 - loss: 0.4740 - val_accuracy: 0.7580 - val_loss: 0.4839 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 370ms/step - accuracy: 0.7964 - loss: 0.4635 - val_accuracy: 0.7430 - val_loss: 0.4960 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 372ms/step - accuracy: 0.7867 - loss: 0.4496 - val_accuracy: 0.7520 - val_loss: 0.4913 - learning_rate: 5.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.7860 - loss: 0.4428\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 368ms/step - accuracy: 0.7858 - loss: 0.4431 - val_accuracy: 0.7530 - val_loss: 0.4797 - learning_rate: 5.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 368ms/step - accuracy: 0.7796 - loss: 0.4492 - val_accuracy: 0.7650 - val_loss: 0.4917 - learning_rate: 2.5000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 372ms/step - accuracy: 0.8030 - loss: 0.4298 - val_accuracy: 0.7480 - val_loss: 0.5279 - learning_rate: 2.5000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 368ms/step - accuracy: 0.7813 - loss: 0.4473 - val_accuracy: 0.7580 - val_loss: 0.4683 - learning_rate: 2.5000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.7948 - loss: 0.4493\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 373ms/step - accuracy: 0.7949 - loss: 0.4489 - val_accuracy: 0.7620 - val_loss: 0.4775 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 367ms/step - accuracy: 0.8156 - loss: 0.4168 - val_accuracy: 0.7530 - val_loss: 0.5147 - learning_rate: 1.2500e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 367ms/step - accuracy: 0.8148 - loss: 0.4002 - val_accuracy: 0.7680 - val_loss: 0.4758 - learning_rate: 1.2500e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 392ms/step - accuracy: 0.8150 - loss: 0.4155 - val_accuracy: 0.7670 - val_loss: 0.4760 - learning_rate: 1.2500e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 405ms/step - accuracy: 0.8114 - loss: 0.4020 - val_accuracy: 0.7620 - val_loss: 0.4672 - learning_rate: 1.2500e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.8194 - loss: 0.4094\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 404ms/step - accuracy: 0.8193 - loss: 0.4094 - val_accuracy: 0.7660 - val_loss: 0.4635 - learning_rate: 1.2500e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 399ms/step - accuracy: 0.8011 - loss: 0.4197 - val_accuracy: 0.7780 - val_loss: 0.4726 - learning_rate: 6.2500e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 372ms/step - accuracy: 0.8130 - loss: 0.4003 - val_accuracy: 0.7700 - val_loss: 0.4663 - learning_rate: 6.2500e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C3()\n",
        "    model.save(\"model_C3.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJdkBM0ABeQV"
      },
      "source": [
        "# PROBLEM C4\n",
        "\n",
        " Build and train a classifier for the sarcasm dataset.\n",
        " The classifier should have a final layer with 1 neuron activated by sigmoid.\n",
        "\n",
        " Do not use lambda layers in your model.\n",
        "\n",
        "# Desired accuracy and validation_accuracy > 75%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ROMw2aXYBebc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Tj-t0wUjBefn"
      },
      "outputs": [],
      "source": [
        "def solution_C4():\n",
        "    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/sarcasm.json'\n",
        "    urllib.request.urlretrieve(data_url, 'sarcasm.json')\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    # Make sure you used all of these parameters or test may fail\n",
        "    vocab_size = 1000\n",
        "    embedding_dim = 16\n",
        "    trunc_type = 'post'\n",
        "    padding_type = 'post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "    training_size = 20000\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    # YOUR CODE HERE\n",
        "    with open('sarcasm.json', 'r') as json_read:\n",
        "        getdata = json.load(json_read)\n",
        "\n",
        "    for i in getdata:\n",
        "        sentences.append(i['headline'])\n",
        "        labels.append(i['is_sarcastic'])\n",
        "\n",
        "    train_sentences = sentences[:training_size]\n",
        "    train_labels = np.array(labels[:training_size])\n",
        "    test_sentences = sentences[training_size:]\n",
        "    test_labels = np.array(labels[training_size:])\n",
        "\n",
        "    # Fit your tokenizer with training data\n",
        "    # YOUR CODE HERE\n",
        "    tokenizer = Tokenizer(num_words=vocab_size,\n",
        "                           oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "    training_seq = tokenizer.texts_to_sequences(train_sentences)\n",
        "    train_sentences_pad = pad_sequences(training_seq,\n",
        "                                    truncating=trunc_type,\n",
        "                                    padding=padding_type)\n",
        "\n",
        "    testing_seq = tokenizer.texts_to_sequences(test_sentences)\n",
        "    test_sentences_pad = pad_sequences(testing_seq,\n",
        "                                   truncating=trunc_type,\n",
        "                                   padding=padding_type)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        # YOUR CODE HERE. DO not change the last layer or test may fail\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        tf.keras.layers.Dense(16, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Callback\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            # Check accuracy\n",
        "            if (logs.get('accuracy') > 0.8 and logs.get('val_accuracy') > 0.8):\n",
        "                # Stop if threshold is met\n",
        "                print(\"\\n\\n\\t=====================================\")\n",
        "                print(\"\\t|| accuracy and val_accuracy > 80% ||\")\n",
        "                print(\"\\t=====================================\\n\")\n",
        "                self.model.stop_training = True\n",
        "    # Instantiate class\n",
        "    callbacks = myCallback()\n",
        "\n",
        "    # Train model\n",
        "    hys = model.fit(train_sentences_pad,\n",
        "                    train_labels,\n",
        "                    epochs=1000,\n",
        "                    validation_data=(test_sentences_pad, test_labels),\n",
        "                    callbacks=[callbacks])\n",
        "\n",
        "    # Show accuracy and validation accuracy value\n",
        "    accu = (hys.history['accuracy'][-1]) * 100\n",
        "    valli = (hys.history['val_accuracy'][-1]) * 100\n",
        "    print(\"\\n\\tAccuracy = \" + \"%.2f\" % accu + \"%\")\n",
        "    print(\"\\tVal_accuracy = \" + \"%.2f\" % valli + \"%\\n\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhvb3fbeBekn",
        "outputId": "d4c92308-ac9b-46a4-da7e-0949c90b6b3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - accuracy: 0.5620 - loss: 0.6831 - val_accuracy: 0.6384 - val_loss: 0.6455\n",
            "Epoch 2/1000\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.6567 - loss: 0.6211 - val_accuracy: 0.7485 - val_loss: 0.5230\n",
            "Epoch 3/1000\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - accuracy: 0.7551 - loss: 0.5049 - val_accuracy: 0.7824 - val_loss: 0.4636\n",
            "Epoch 4/1000\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.7846 - loss: 0.4538 - val_accuracy: 0.7971 - val_loss: 0.4376\n",
            "Epoch 5/1000\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.7987 - loss: 0.4282 - val_accuracy: 0.8016 - val_loss: 0.4222\n",
            "Epoch 6/1000\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.8084 - loss: 0.4116 - val_accuracy: 0.7669 - val_loss: 0.4712\n",
            "Epoch 7/1000\n",
            "\u001b[1m562/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 579us/step - accuracy: 0.8183 - loss: 0.3957\n",
            "\n",
            "\t=====================================\n",
            "\t|| accuracy and val_accuracy > 80% ||\n",
            "\t=====================================\n",
            "\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.8181 - loss: 0.3958 - val_accuracy: 0.8100 - val_loss: 0.4075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\tAccuracy = 81.66%\n",
            "\tVal_accuracy = 81.00%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model = solution_C4()\n",
        "    model.save(\"model_C4.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxV2VnUFBe7E"
      },
      "source": [
        "# PROBLEM C5\n",
        "\n",
        " Build and train a neural network model using the Daily Min Temperature.csv dataset.\n",
        " Use MAE as the metrics of your neural network model.\n",
        " We provided code for normalizing the data. Please do not change the code.\n",
        " Do not use lambda layers in your model.\n",
        "\n",
        " The dataset used in this problem is downloaded from https://github.com/jbrownlee/Datasets\n",
        "\n",
        "# Desired MAE < 0.19 on the normalized dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "otqMFWxqBfHI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import urllib\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bj6mmVQRBfKc"
      },
      "outputs": [],
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    series = tf.expand_dims(series, axis=-1)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
        "    return ds.batch(batch_size).prefetch(1)\n",
        "\n",
        "def solution_C5():\n",
        "    data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n",
        "    urllib.request.urlretrieve(data_url, 'daily-min-temperatures.csv')\n",
        "\n",
        "    time_step = []\n",
        "    temps = []\n",
        "\n",
        "    with open('daily-min-temperatures.csv') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        next(reader)\n",
        "        step = 0\n",
        "        for row in reader:\n",
        "            temps.append(np.float32(row[1]))\n",
        "            time_step.append(step)\n",
        "            step = step + 1\n",
        "\n",
        "    series = np.array(temps)\n",
        "\n",
        "    # Normalization Function. DO NOT CHANGE THIS CODE\n",
        "    min=np.min(series)\n",
        "    max=np.max(series)\n",
        "    series -= min\n",
        "    series /= max\n",
        "    time=np.array(time_step)\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    split_time=2500\n",
        "\n",
        "    time_train = time[:split_time]\n",
        "    x_train = series[:split_time]\n",
        "    time_valid = time[split_time:]\n",
        "    x_valid = series[split_time:]\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    window_size=64\n",
        "    batch_size=256\n",
        "    shuffle_buffer_size=1000\n",
        "\n",
        "    train_set = windowed_dataset(\n",
        "        x_train, window_size, batch_size, shuffle_buffer_size)\n",
        "    print(train_set)\n",
        "    print(x_train.shape)\n",
        "\n",
        "    valid_set = windowed_dataset(\n",
        "        x_valid, window_size, batch_size, shuffle_buffer_size)\n",
        "\n",
        "    model=tf.keras.models.Sequential([\n",
        "        # YOUR CODE HERE.\n",
        "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1),\n",
        "    ])\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "    model.fit(train_set, epochs=100, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3), tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.0001)], validation_data=valid_set)\n",
        "\n",
        "    # Get the model's prediction on the test set\n",
        "    test_pred = model.predict(valid_set).flatten()\n",
        "\n",
        "    # Only use the first 500 samples of the test set\n",
        "    test_pred = test_pred[:len(x_valid)]\n",
        "    x_valid = x_valid[:len(x_valid)]\n",
        "\n",
        "    # Plot the predictions\n",
        "    plt.plot(test_pred, 'r-', label='Prediction')\n",
        "    plt.plot(x_valid, 'b-', label='Truth')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rnvYkrqUBfO8",
        "outputId": "89a9a8c9-ac18-4627-cf8b-d586261b3360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float32, name=None))>\n",
            "(2500,)\n",
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0919 - mae: 0.2723 - val_loss: 0.0195 - val_mae: 0.1282 - learning_rate: 0.0010\n",
            "Epoch 2/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\srini\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0160 - mae: 0.1003 - val_loss: 0.0092 - val_mae: 0.0830 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0136 - mae: 0.0933 - val_loss: 0.0083 - val_mae: 0.0791 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0109 - mae: 0.0818 - val_loss: 0.0078 - val_mae: 0.0770 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0104 - mae: 0.0800 - val_loss: 0.0079 - val_mae: 0.0773 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0103 - mae: 0.0793 - val_loss: 0.0072 - val_mae: 0.0738 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0100 - mae: 0.0783 - val_loss: 0.0073 - val_mae: 0.0737 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m 4/10\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0103 - mae: 0.0794\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0100 - mae: 0.0782 - val_loss: 0.0074 - val_mae: 0.0744 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0101 - mae: 0.0784 - val_loss: 0.0073 - val_mae: 0.0742 - learning_rate: 5.0000e-04\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# The code below is to save your model as a .h5 file.\n",
        "# It will be saved automatically in your Submission folder.\n",
        "if __name__ == '__main__':\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "    model=solution_C5()\n",
        "    model.save(\"model_C5.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
